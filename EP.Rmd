---
title: "EP MAE0699 - Tópicos de probabilidades"
author: |
  | Fabricio Kassardjian    nusp:2234961
  | Robert Mota dos Santos  nusp:9039927
date: "15 de maio de 2019"
header-includes:
 - \usepackage{amsmath}
 - \usepackage{bbm}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
options(tinytex.verbose = TRUE)
```

```{r load_lib, include=FALSE, cache=FALSE}
source("EP_aux.R", encoding = 'utf-8')
library(igraph) 
N = 200 # mudando o tipo de matriz aumentou a eficiencia
ns = 8:10  # range de tamanho de matrizes para teste
prob = 0.4 # probabilidade de ligacao (gerar um aleatorio entre 0.25 e 0.75)
```


# Introdução

O trabalho se refere a estudar as curvas de distribuição para $T(v)$ e $C(v,w)$, onde **T** representa o caminho mais curto de retorno ao vértice *v* e **C** o caminho mais curto entre os vértices *v* e *w*. O modelo de Erdo-Rényi é utilizado para gerar os grafos aleátorios com *n* vértices e probabilidade *p* de ligação entre cada par de vértices.

## Modelo 2
O modelo escolhido para o teste foi usando conexões não direcionadas e preguiçoso. O fato de ser preguiçoso implica que existem conexões para continuar no mesmo vértice. Além disso fica determinado que cada connexão só pode ser usada uma unica vez para cada caminho testado, assim evita-se que a distribuição **T** tenha apenas valores 1 e 2. Como as conexões são aleatórias podem existir vértices isolados e também como não pode ser utilizado a mesma conexão para voltar podem existir valores de **T** e **C** que podemos considerar $\inf$.

# Metodologia
## Estimação das distribuições
Para o teste primeiro inicia-se uma matriz *A* representando com **TRUE** quando a ligação entre os vértices está presente e **FALSE** quando não há ligação. A linha *i* da matriz representa o vértice de saída e a coluna *j* representa o vértice de chegada. Como o modelo é preguiçoso pode existir **TRUE** na diagonal principal da matriz, e pelo fato das conexões não serem direcionadas a matriz é simétrica.

Exemplo de matriz de conexões para 5 vértices com probabilidade de conexão 0.4:
```{r matrix_example, echo=TRUE}
n = 7
A = generateMatrix(n, 0.4)
print(1*A) #1* para deixar em formato numerico

plot(graph_from_adjacency_matrix(A, mode = 'undirected', weighted = TRUE))
```

Para cada mariz gerada é testado para cada vértice o menor caminho de volta, usando uma busca em profundidade dos caminhos possíveis da matriz e armazenado o vetor com a contagem de cada valor para **T** encontrado. O mesmo é feito para cada combinação de vértices possíveis para encontrar os valores de **C**. Os caminhos podem ter tamanhos até $n$ e iremos considerar o valor $n+1$ como sendo infinito.

Exemplo de valores de $T(v)$ para cada vértice de **A**
```{r T_example, echo=TRUE}
for(i in 1:n) {
  Ti = findPath(i,i,A,0,n+1)
  cat(sprintf("T(%d) = %d\n",i, Ti))
}
```

Será gerado para cada tamanho de $n \in \{6,7,8,9,10,11,12\}$ uma amostra de $`r N`$ matrizes e feita uma contagem para cada valor de **T** encontrado. A distribuição é estimada tirando a média da contagem por $n * `r N`$. Assim:

$$\hat{P}(T=k) = \frac{1}{n*`r N`} \sum_{i=1}^{n*`r N`} \mathbbm{1}_{(T=k)}$$

Para a distribuição de *C* é usado processo similar mas como temos as combinações entre os pares serão estimados $n * n$  valores para cada matriz, assim:

$$\hat{P}(C=k) = \frac{1}{n^2 *`r N`} \sum_{i=1}^{n^2 *`r N`} \mathbbm{1}_{(C=k)}$$

## Tamanho da amostra
Para determinar um tamanho bom de amostra para a aproximação da estimação, fixamos $n = 8$ e geramos a distribuição e o gráfico para alguns tamanhos de amostra ($N \in \{25, 50, 75, 100, 150, 200, 250, ..., 750, 800\}$). Depois calculamos a soma das diferenças ao quadrado entre os valores de cada distribuição e colocamos em um gráfico. No gráfico pode ser verificado se houve convergência e com que tamanho de amostra podemos considerar a convergência.
$$erro = \sum_{i = 1}^{n+1} \big(P(T=k) - P'(T=k)\big)^2$$
onde $P(T=k)$ é a probabilidade para o tamando de amostra atual e $P'(T=k)$ a probabilidade da amostra anterior.

## Teste de aderência
Após determinar um função de densidade de probabilidade que define a distribuição para os valore de $P(T=k)$ e $P(C=k)$, usaremos um teste de aderência para validar a hipótese. Testamos a $H_0$: população segue distribuição proposta contra a $H_1$: população tem outra distribuição. Para ta usaremos a seguinte estatística de teste:
$$\chi^2 = \sum_{i=1}^{K}\frac{(O_{i} - E_{i})^2}{E_{i}}$$
Onde $O_{i}$ são as frequências observadas na simulação, $E_{i} = P(T=i) \times N$ a frequência esperada e $K$ representa a quantidade de pontos da distribuição. Assim $\chi^2$ tem uma distribuição chi-quadrada com $K-1$ graus de liberade.
Com o teste calculado definimos a região critica como $RC = (c, \infty)$ onde $P(\chi^2_{s-1} > c) = \alpha$, sendo $\alpha$ o nível de significância para o nosso teste.

Dessa forma após as simulações e escolhida uma distribuição provável que explique a frequencia observada, é feita a soma dos calculos das diferenças, e o resultado comparado com $c$. Se o valor calculado for maior que $c$ rejeitamos nossa hipótese $H_0$ com o nível de significância escolhido, e a distribuição selecionada não é aderente as observações. Mas se o valor calculado for menor que $c$ então não rejeitamos $H_0$ e podemos considerar que a variável aleatória $T$ tem a distribuição do modelo sugerido.

# Simulação
## Tamanho da amostra
Gráfico para vários tamanhos de amostra com $p = `r prob`$:

```{r tam_amostra, echo = FALSE}
v = testeAmostras(n = 8, c(25, 50, 75, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800), p = prob, silent = TRUE)
```
Pelo gráfico podemos considerar uma amostra com tamanho `r N` razoável para as estimações de distribuição.

## Distribuições para T

Valores estimados e gráficos da distribuição, usando `r N` amostras, e $p = `r prob`$

```{r gera_dist_T, echo = FALSE}
d = testeSamplesT(range_n = ns, sampleSz = N, p = prob, silent = TRUE, nographs = TRUE)
printGraficos(d)
```

## Proposta de distribuição proposta para T
Ao realizarmos os testes, percebemos que nossa distribuição aparenta ter caracteristicas e formas de algumas distribuições conhecidas, sendo elas: Poisson, Exponencial e Geométrica. Neste caso vamos tentar identificar qual distribuição é mais 'próxima' da nossa distribuição e quais são os melhores paramêtros da distribuição escolhida.


# Premissas iniciais:
Nossa simulação é um processo discreto, além disso realizamos algumas mudanças em nossas distribuições de T. Primeiramente, retiramos a observação 2 de nosso processo, porque o problema definido não permite que o tempo minimo de volta seja 2, assim: $O_{2} = 0$.Retiramos, também, a observação 1 porque, de fato, $P(O_{1}) = p$, pois o problema é definido para podermos voltar ao mesmo nó com probabilidade $p$ , fica bem definido assim $P(O_{1}) = p$
e por fim e não menos importante, retiramos $T_{inf}$ porque ele inviesa nossa distribuição esperada.

***

Caracteristicas da simulação:
- Número de vértices: 10
- Número de repetições: 1000
- Probabilidade de conexão entre vértices: 0.4

***

A distribuição sem as observações citados tem uma distribuição reescalada na forma:

```{r isolate_dist, echo = FALSE}
distT = d[[1]]$dadosAcum
nd = d[[1]]$n
dT = distT[3:nd]
dTp = dT / sum(dT)
dTP = dT / sum(distT)
#lambd = sum(1:length(dT) * dT)/sum(dT) 
#geo = 1/lambd
plot(c(NA,NA,dTp), x = 1:nd, col="blue", type = "b", xlab="N de Vertices", ylab="Probabilidade")
grid(nx = NULL, ny = NULL, col = "darkgray", lty = "dotted", lwd = par("lwd"), equilogs = TRUE)
```


<!-- ![](Distribuicao_reescaled.png) -->

### Parâmetros da distribuição:
Para encontrar os parametros das distribuição vamos usar as leis dos grandes números que diz que a média da amostra converge para a média da população quando o tamanho da amostra cresce, em outras palavras:
$$ \lim_{n->\infty}\hat{\mu_{n}} \rightarrow \mu $$

Usaremos estas premissas para encontrar os parâmetros da distribuição .
Sendo assim devemos conhecer a esperança da distribuição geométrica,poisson e exponêncial:

$$\begin{aligned}
E(X\sim Geo(p)) = \frac{1}{p} \\
E(X\sim Exp(\lambda)) = \lambda \\
E(X\sim Pois(\lambda)) = \lambda \\
\end{aligned}$$ 
A partir da simulação encontramos os parâmetros das distribuições como se segue:

Geométrica | Exponêncial | Posisson
------------- | ------------- | -------------
   E(x) = 0.834  |   E(X) = 1.199    |   E(x) = 1.199 
 
***


Realizando simulações com as premissas citadas e com os parâmetros encontrados obtemos os seguintes distribuições:

\begin{table}[ht]
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{x}              & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10} \\ \hline
\textbf{Exponêncial}    & 1.2076     & 0.3610     & 0.1079     & 0.0326     & 0.0096     & 0.0029     & 0.0003     & 7.70e-05    \\ \hline
\textbf{Geométrica}     & 0.8282     & 0.1423     & 0.0244     & 0.0042     & 0.0007     & 0.0001     & 2.13e-05   & 3.66e-06    \\ \hline
\textbf{Poisson}        & 0.3610     & 0.2179     & 0.0877     & 0.0265     & 0.0064     & 0.00123    & 0.0002     & 3.35e-05    \\ \hline
\textbf{Dist. Simulada} & 0.8273     & 0.1435     & 0.0247     & 0.0036     & 0.0009     & 0          & 0          & 0           \\ \hline
\end{tabular}
\end{table}

Para chegar nos resultados da tabela acima foram utilizados o seguinte calcúlos:  $$E(T) = \sum_{i=1}^{n}T_{i}*P(T=i) \rightarrow p = \frac{1}{E(T)}$$ para cada uma das distribuições.

A seguir o resultado de cada uma das distribuições com os parâmetros encontrados:

![](dist_tog.png)

Legenda:
Pontos roxos: Distribuição Exponencial
Pontos Azuis: Nossa distribuição Simulada 
Pontos Verdes: Distribuição Geométrica 
Pontos Pretos: Distribuição Poisson 



A partir destas distribuições tomamos aquela que possui menor distância entre a distribuição simulada e as distribuições propostas.

Como pode ser visto na imagem acima a distribuição que será assumida será a Geométrica. Por se 'encaixar' melhor em nossa distribuição simulada.

Em seguida iremos realizar o teste de $\chi^2$ para avaliarmos se estamos cometendo o erro na escolha da distruibuição. 

##Teste de aderência:
Com nossa função proposta em mãos, podemos realizar o teste $\chi^2$ com $\alpha = 5%$ de tolerância. Para avaliarmos se estamos ou não comentendo o erro de escolher a distribuição Geométrica com parâmetro(p=0.834).


$$ \chi^2 = \sum_{i=1}^{K}\frac{(O_{i} - E_{i})^2}{E_{i}} $$
Onde $O_{i}$ são as frequências observadas na simulação e $E_{i} = P(T=i)\times N$ com $T\sim (Geometrica)$. K representa o número de repetições.

## Teste de aderência para T

![](dis_x2.jpg) 

Hipótese nula: Distribuição Geométrica com parâmetro p = 0.834 seja igual a distribuição T simulada.
Hipótese alternativa:  Disttribuição Geométrica com parâmetro p = 0.834 seja Diferente a distribuição T simulada.

Nossa região critica para $\alpha = 5%$ é $RC=\{x:\mathbb{R}, (12.59159,+\infty) \}$ 
O valor de $\chi^2(s=(6)) = 0.2834055$. Sendo assim concluímos que assumimos que nossa distribuição geométrica tem boa aderência com erro de $\alpha = 5%$. Como nosso $\chi^2 \notin RC$ sendo assim não reijetamos a nossa hipótese nula.

Notas: Consideramos 6 graus de liberdade pois havíamos retirado as observações 1,2 e 11 sendo assim teríamos 7 elementos.


##Distribuição Reescalada e distribuição simulação
Queremos agora, voltar para distribuição original a partir da distribuição reescalada. Veja abaixo ambas as distribuição:

![](Both_dist.png) 

Legenda
Azul: Distribuição da simulação reescalada
Cinza: Distribuição da simulação original

Foi necessario reescalar a distribuição e retirar dados pois a mesma iria interferir na comparação com uma distribuição já conhecida, que neste caso foi a geométrica. Portanto, temos que voltar a distribuição reescalada para distribuição original.

```{r}
#n = 10
#dT = distT[3:n] ##Retiramos os nós 1 e 2 (Premissa)
#dTp = dT / sum(dT) ##Distribuição reescalada (Azul)
#dTP = dT / sum(distT) ##Distribuição Original considerando todos os nós.
```

Como queremos sair da distribuição Azul(reescalada) para a distribuição cinza(orginal), temos a seguinte equação:

$$dTP[k] = \frac{dTp[k]\times \sum_{i=1}^{n}dT[i]}{\sum_{i=1}^{n}distT}, k=1,2,..,n$$

Realizando esses passos podemos encontrar a distribuição reescala para a forma original:

![](Both_origin.png) 

Agora é possivel reeconstruir toda a distribuição da simulação,porque sabe-se que P(T=2)=0 e P(T=1) = p = 0.4 e que $P(T = ' \infty ') = 1 - P(T<=n)$, todas as informações foram citadas na seção de premissas.

E finalmente temos nossa distribuição reconstruida completamente.

![Distribuição completa com base na distribuição geométrica](LASTT.png)

## Distribuições para C
Valores estimados e gráficos da distribuição. Como a quantidade de testes aumenta em $n$ vezes para a distribuiçao C, reduzimos a quantidade de matrizes geradas pela metade, e portanto usamos uma amostra de tamanho `r N/2` com $p = `r prob`$.

```{r gera_dist_C, echo = FALSE}
e = testeSamplesC(range = ns, sampleSz = N/2, p = prob, silent = TRUE, nographs = TRUE)
printGraficos(e)
```

## Teste de aderência para C
